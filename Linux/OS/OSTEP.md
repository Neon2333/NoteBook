# OS概述

### 操作系统解决的几个主要问题：

* **CPU虚拟化**
* **内存虚拟化**
* **并发**
* **持久化**

---

# CPU虚拟化

## 1.分时共享

### （1）CPU虚拟化的概念

在某一时刻在一个CPU上只能运行一个进程，即使现代CPU都有多个核（实际CPU），但核心数依旧是有限的。为了在一个核上运行多个进程。利用**分时共享技术**。

每个进程只能在特定的**时间片**才能占用CPU，CPU上的进程不断快速切换，从而造成多个进程同时在某一个CPU上运行的假象。

### （2）怎样切换进程

**上下文切换**

### （3）何时切换进程

由OS上的**进程调度程序**决定

进程调度算法



## 2. 受限执行

应满足：应用程序不能拥有对CPU的所有控制权，必须要受控，只能访问该访问的资源。

为此，CPU具有两种模式：内核态、用户态。

当CPU处于内核态时，可以访问所有资源。当CPU处于用户态时，则只能访问有限的资源。

### 直接执行过程：

> * OS在进程表中添加要启动的进程的表项
> * 在内存中为该进程开辟空间，将elf按照对应关系加载到内存。
> * 跳转到跳转到程序入口点执行开始执行。



## 3. 系统调用

OS为了向应用程序提供一些操作高权限资源的功能，会



## 4. 上下文切换

### （1）时钟中断



### （2）上下文切换过程



## 5. 进程调度

### （1）概念



### （2）性能指标



### （3）FIFO



### （4）SJF——最短任务优先算法



### （5）PSJF——抢占式最短任务优先算法



### （6）轮转算法



### （7）MLFQ——多级反馈队列算法



### （8）比例份额调度算法

#### 彩票调度算法





#### 步长调度算法









---

# 内存虚拟化

## 14. C库内存操作函数

### （1）进程的内存空间结构

![](https://raw.githubusercontent.com/WangKun233/ImageHost/main/mmmm.PNG)

图中自下而上地址从低到高，从低到高依次为：代码段、数据段、堆、共享库、栈、内核。

栈空间由编译器隐式管理，堆内存由用户手动申请和释放。

该空间结构是虚拟内存空间，是进程私有的、连续的一块内存，是OS通过内存管理模拟出的一块空间，实际的物理内存可能是多块的、不连续的。

### （2）申请堆内存

```C++
void* malloc(size_t size);
```

> 返回值——void*指针，需强转为需要类型
>
> size——需要申请的堆内存的大小（字节）
>
> > * 代码中，size不要用具体数值，用sizeof(Typename)替代。
> >
> > * 其中sizeof为编译时操作符，不是函数，前者在编译阶段运行，后者需要在执行阶段进行压栈、出栈。
> >
> > * 注意，为字符串str申请堆内存时：char* pstr = malloc(strlen(str) + 1)。需要多申请1B给字符串末尾的'\0'

```c++
void* calloc(unsigned int num, unsigned int size);
```

> 申请num个连续的长度为size的堆内存，且自动将申请的内存空间初始化为0
>
> 返回值——指针

```C++
void* realloc(void* ptr, size_t size);
```

> 创建一个长度为size的堆内存，将ptr指向的堆内存的内容拷贝到新开辟的长度为size的内存中，并返回指向开辟的新内存的指针
>
> ptr——指向存储待拷贝的内容堆内存的指针
>
> size——重新开辟的堆内存的长度

### （3）释放堆内存

```C++
free()
```

> 传入参数——malloc/calloc/realloc返回的指针
>
> 注意：只能释放一次、只能释放由malloc/calloc/realloc申请的堆内存

### （4）malloc底层相关

#### 概念

* malloc、realloc、calloc、free这些函数都是glibc库函数，底层是Linux内核中的C函数brk()和sbrk()，而brk和sbrk基于系统调用sys_brk()和mmap()。
* glibc库是GNU发布的C运行库。glibc是linux系统中最底层的api，几乎其它任何运行库都会依赖于glibc。glibc除了封装linux操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现。
* 用户对于内存的操作应该使用malloc等函数，而不要试图使用brk()和sbrk()。

#### brk

* brk(programm break)表示程序代码的代码和数据到此结束，后面的部分只在运行时使用。Linux系统中，只存储elf文件中的代码段、数据段内容。

  ![image-20220908090039844](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220908090039844.png)

  Linux系统在创建进程时，每个进程都有一个brk，指向堆栈的末尾（高地址）。

  在进程在初始还没有申请堆内存时，brk指向数据段data的末尾。

#### brk()和sbrk()

​	brk()和sbrk()改变brk指针的位置

* 调用brk()申请堆内存，brk向高地址移动。调用sbrk()释放堆内存，brk向低地址移动。

  ```c
  #include<unistd.h>
  int brk(void* addr);	//申请堆内存
  void* sbrk(intptr_t increment);		//释放堆内存
  ```

#### sys_brk和mmap

* 两者都是用来申请堆内存的系统调用

  sys_brk将brk向高地址移动，mmap在堆和栈之间的文件映射区申请一块空闲虚拟内存。

  这两种方式申请的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，OS负责分配物理内存，并建立虚拟内存到物理内存的映射关系。

* malloc小于128k的内存时，调用sys_brk()申请

  malloc大于128k的内存时，调用mmap申请，在堆和栈之间申请一块空闲内存，对应独立内存，而且初始化为0。

  为什么要用两种方式申请内存？

  > brk管理的堆内存只有高地址被释放后才能释放低地址，而mmap分配的内存可以各自互不影响的释放。
  >
  > 例如：brk先后分配了p1和p2两块内存，p1不使用了需要释放，p2还在使用，这种情况下是无法释放p1的。因为只有一个brk无法同时指向两个位置。

## 15. 机制——地址转换

### （1）概念

* **地址转换**——将虚拟地址转化为物理地址

* **基址寄存器(base register)**——程序编写、编译时都按照程序拥有私有的一块连续内存进行。运行时，不论是PC内存储的指令的地址还是数据的存储地址都是虚拟地址，经过与基址寄存器内存储的基址求和再得到实际的物理地址，从物理地址取指令或读写数据。存储一块虚拟内存的物理首地址。

  **physicalAddr = virtualAddr + base **

* **界限寄存器(bound register)**——用来判断进程访问的地址是否超出分配的范围，确保进程无法访问其地址空间外的内存（若进程可以随意修改内存，就能够轻松地作出可怕的事情，比如重写陷阱表接管系统）

  > 两种处理方式：
  >
  > * 存储虚拟地址的界限，在用虚拟地址转化为物理地址之前，先用虚拟地址判断是否超出界限
  > * 存储物理地址的界限，在用虚拟地址转化为物理地址之后，用物理地址判断是否超出界限

* 地址转换机制完全由硬件完成，CPU上有负责内存管理的部分**MMU（内存管理单元）**。MMU上有一对基址寄存器和界限寄存器。

### （2）为了实现地址转换，CPU需要支持的功能

* 每个CPU上都要有基址寄存器、界限寄存器

* CPU要能提供特权指令，在内核模式下能够修改基址寄存器和界限寄存器的值。

  以便，可以在CPU处理上下文切换时，可以将基址寄存器和界限寄存器的值修改为待切换的进程的基址寄存器、界限寄存器的值（从进程结构中获取）。

* CPU要能产生异常

  > * 当用户程序试图访问超出进程的地址范围的内存（界限寄存器）进行越界访问时，CPU要能产生异常，调用越界访问异常处理程序进行处理
  > * 当用户程序试图访问基址寄存器或界限寄存器时，CPU要能触发**用户模式尝试执行特权指令**异常，并调用**用户模式尝试执行特权指令异常处理程序**

### （3）当CPU支持了以上功能后，OS需要增加的功能

* 进程创建时，OS要能为进程分配内存（虚拟内存）。通过**空闲列表(free list)**管理内存的分配和回收，将在后面详细讨论。

* 上下文切换时，OS要能保存基址寄存器、边界寄存器的值到进程结构或进程控制块PCB中，或从进程结构或进程控制块PCB中恢复到基址寄存器、边界寄存器中。

* CPU触发异常时，OS要能够调用相应的异常处理程序。如：越界异常处理程序。

  异常处理程序的调用通过异常表，异常表是在OS启动时就加载的，保存各种异常对应的应调用的处理程序。

## 16. 分段——虚拟内存向物理内存进行映射的方案一

### （1）为什么要引入分段？

不引入分段的地址转换是在偏移、基址寄存器值、偏移寄存器值的基础上将某个进程的**整个虚拟地址空间**映射到物理地址。

这会产生两个问题：

* 堆和栈之间的空闲区域将直接映射到物理地址，造成内存浪费
* 将某进程的整个虚拟地址空间映射到物理空间，需要物理内存管理程序在物理内存中寻找能够装下整个地址空间的一块连续物理内存，当找不到时就无法分配内存。

### （2）相关概念

* 分段就是将虚拟空间按照逻辑的不同分成若干段：代码段、堆、栈，每个段是地址空间里一个连续定长的区域，各个段分别向物理内存进行映射。每个段都有自己的一对基址寄存器、界限寄存器用来存储该段自己的基址和范围。

* MMU支持分段需要3对基址寄存器、界限寄存器。

* 分段机制可以将不同的段独立地映射到不同的物理区域（通过每个段都有自己的基址寄存器和界限寄存器），只有已用的内存才会按照逻辑被分到某个段中映射到物理内存，避免了虚拟空间中未使用的部分占用物理内存。

* **段物理地址=基址寄存器+段内偏移**

* 硬件在分段机制下的地址转换使用**段寄存器**。一种常见方式，称为**显式方式**

> * 前2位标识段类型，告知硬件：00-代码段，01-堆，10-栈
> * 后12位标识段内偏移
>
> * 硬件计算段物理地址的过程：
>
>   ![image-20220912042054020](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220912042054020.png)

隐式方式，硬件通过地址产生的方式来确定段类型（未详细解释）。

### （3）分段机制支持内存共享

为了节省内存，在地址空间之间共享某些内存段。主要是**共享代码段（共享库/动态库）**，因为代码段是**只读**的，共享只读的部分不会破坏隔离，因为没有修改内存。OS将共享内存块在不同进程间共享，但进程仍认为自己是在独享内存。

为了实现这种内存共享，每个段添加了**保护位**，标识某段的访问权限，如是否能够读写该段或是执行其中代码。保护位标记为只读的段可以被共享。

增加了访问权限以后，除了通过界限寄存器判断虚拟地址是否越界，还要通过保护位判断访问权限，若用户程序试图写入标识为只读的段或试图执行非执行段，CPU会触发异常，让OS来处理错误。

### （4）为了实现分段，OS需要支持的功能

* 和地址转换中上下文切换时需要保存、恢复基址寄存器、界限寄存器的值相同。OS需要在上下文切换时，保存、恢复段寄存器的值。（段类型、段内偏移）

* OS要管理空闲内存

  如果需要被管理（分配、回收）的内存都被划分为等大小的单元，那么管理起来就会方便很多。只要用数据结构维护这些固定大小的单元的列表，若有内存请求，就返回列表的第一个单元。

  但实际中，段的大小是不定的，给段分配空间时，就比较难找到恰好满足段大小要求的一块空间。找到一块大于需求的段的空间，分配给段以后，还剩下一块，这一块由于太小而难以分配给新的段，这就是**外部碎片**。（因为段的大小不一，段与段之间将会产生很多空闲的小洞，因为太小难以分配给新的段，被称为外部碎片。）

* OS将会利用算法，尽量解决外部碎片的问题：

  ①紧凑物理内存：将段与段之间的碎片合并成大的连续的空间

  ②空闲内存管理算法：将空间碎片以合理的算法分配给待分配的段

## 17. 空闲内存管理

### （1）为什么要对空闲的物理内存进行管理

#### 外部碎片

外部碎片指从空闲列表中分配给用户请求的空间大小后，空闲列表中剩下的太小的无法满足请求大小的内存块，虽然可能总的空闲空间之和满足请求大小。可通过合并空闲空间或使用分页机制消除外部碎片。

外部碎片不可避免。

#### 内部碎片

当内存分配程序将某块内存分配给程序时，若分配的空间 > 程序占用的空间，则这块分配的空间会多出一部分空闲空间，称为内部碎片。

内部碎片指分配的某块堆内存空间大于实际请求的堆内存大小，多出来的这块内存就是内部碎片。分配后的这块内存在被释放前都不能再被OS重新使用。可通过合理的内存分配算法减少内部碎片。内部碎片一旦产生，除非释放这块内存重新给请求分配空间，否则无法消除。

#### 磁盘碎片

磁盘上的外部碎片（即平时所说的磁盘碎片，磁盘碎片清理工具只能清理磁盘上的外部碎片，清除不了磁盘上的内部碎片，除非改变文件系统的分配单位即簇的大小，使之是一个文件大小的整数倍。）

### （2）空闲列表——管理空闲堆内存的数据结构

空闲列表的概念示意图：

![空闲列表](https://raw.githubusercontent.com/WangKun233/ImageHost/main/%E6%9C%AA%E5%91%BD%E5%90%8D%E5%9B%BE%E7%89%87.png)

### （3）内存分配程序

#### **机制1——分割、合并**

此处仍以空闲列表的概念图展示分割、合并过程。

申请内存时，内存分配程序会执行所谓**分割（splitting）**动作：找到一块大小>=所需大小的空闲空间，将其分割，第一块返回给用户，第二块留在空闲空间中。例如：

> 原始空闲列表如17-(2)中图所表示，用户申请1B空间，假设内存分配程序选择addr范围为20~30的空间进行分割。则malloc()返回addr=20，且空闲列表会变为：
>
> ![image-20220923110836157](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220923110836157.png)
>
> 可见，空闲列表的第二个节点，地址addr=21，长度len变为了9。

> 针对17-(2)中图，假设用户调用free(10)将addr=10,len=10的堆内存归还。若只是简单的将该块内存嵌入空闲列表中，将得到下图的结果：
>
> ![image-20220923112654814](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220923112654814.png)
>
> 问题发生了：尽管现在addr从0~30的空间都空闲，但却被分割成了3个长度为10的块。若此时用户想要malloc申请长度为20的空间，则无法找到满足长度需要的空间而失败。

为此，内存分配程序会在释放一块内存时，**合并**空闲空间：查看要归还的内存的地址和邻近的内存块，若要归还的内存和邻近内存块（一侧或两侧）完全相邻中间没有其他未归还的内存，就将它们合并成一个较大的空闲块。最后如图：

![image-20220923113403623](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220923113403623.png)

通过合并，分配程序能够确保有大块的内存空间满足用户的申请需求。

#### **机制2——头块**

头块紧邻malloc分配的每块内存之前，因此内存分配程序会从空闲列表寻找、分割出一块大小为`申请大小 + sizeof(header_t)`的堆内存。

```C
ptr=malloc(20);
```

![image-20220923171932868](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220923171932868.png)

ptr指向返回给用户程序的堆内存，大小为20B。在这块内存之前跟着一个头块，定义为：

```c
struct header_t{
    int size;
    int magic;
}
```

因此，头块的大小`sizeof(header_t) == 8B`。

free()释放内存时，会首先由ptr计算出hptr的值，然后获取size和magic进行验证，若无误就将头块和用户使用的内存都归还给空闲列表。

```c
void free(void *ptr) {
    header_t *hptr = (header_t *)(ptr - 1);		//hptr_addr == ptr_addr - 8B
    assert（hptr->magic == 1234567);
}
```

#### 机制3——空闲链表

* 空闲列表以链表为实现。链表的节点紧邻在空闲的堆内存之前，将空闲内存串起来，每个节点的大小为8B。

* **节点的结构：**

```c
typedef struct node_t{
    int size;	//当前紧邻的空闲块的大小
    struct node_t* next;	//32位地址空间下，指针4B
}node;
```

* **空闲链表**

  库通过调用mmap（大于128kb调用mmap，小于调用sbrk），从OS申请了一块4kb的堆内存。通过空闲列表管理这块内存，初始时因为这块内存是连续的，所以空闲列表只有一个头结点、一块空闲堆内存。

  > ![image-20220923215805479](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220923215805479.png)
  >
  > mmap申请了4kb内存，由于节点占用了8B，所以可被用户申请的内存为4088B。
  >
  > ![image-20220923220049984](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220923220049984.png)

* **内存分割**

  假设现在想要分配100B的一块空间，通过分割策略，从剩下的4088B空闲空间内分割出108B的一块，将head->size改为4088-108，同时head也移动到4088-108新地址处。分割出来的108B，其中8B作为块头header_t，header_t->size = 100，header_t->magic=***。

  这样分割了3次后，分配了三块内存的堆空间：

  ![image-20220923223810601](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220923223810601.png)

* **内存释放**

  `free(16500)`过程：

  释放上图中sptr=16500位置的内存块，将16500处的头块改为node_t结构，size=100，链表头插法插入节点，所以next=head（当前的head还未移动，head=3764），然后将head移动到新的空间链表的头结点处，即(16500-8)B处。free(16500)后内存结构，如下图所示：

  ![image-20220925161832023](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220925161832023.png)

* **合并紧邻的空闲内存块**

遍历空闲链表，将紧邻的空闲块合并（包括空闲块的节点node_t的8B）。一个空闲块只会有一个node_t，最终又恢复到初始状态的只有一个node_t和一段连续内存的状态：

![image-20220923215805479](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220923215805479.png)

#### 机制4——堆增长

当用户程序在运行过程中发现从OS申请的堆内存不够大时：

大多数传统的内存分配程序会从很小的堆开始，当分配的空间耗尽时，再向OS申请更大的空间。这一过程中内存分配程序进行了某种系统调用令堆内存增长，如UNIX系统中的sbrk()。

OS在执行系统调用sbrk()时，会寻找空闲的物理内存页，将它们映射到申请内存的进程的地址空间中，并返回新的堆的末尾地址（堆内存地址增长方向由低向高）。这样该进程就有了更大的堆，新的内存申请得到满足。

#### 机制5——堆内存分配算法

* **最小匹配**——遍历空闲列表，找到所有>=待分配空间大小的内存块，返回其中最小的那块。并将多余空间返还给空闲列表。

* **最差匹配**——遍历列表，找到最大的块进行分割，一部分作为待分配空间返回给用户，剩下的部分返还给空闲列表。

* **首次匹配**——不用遍历，找到第一个>=待分配空间大小的内存块，分割，将一部分返回给用户，剩下返还给空闲列表。

* **下次匹配**——不用遍历，多维护一个指针，指向上次遍历列表结束的位置，下次从指针指向处开始，而不是一味从头开始遍历列表。避免了对开头频繁的分割。

* **伙伴算法**——对空闲堆内存空间进行二分，分得的2个部分称为伙伴。再取其中一个进行二分，直到所得是能满足要求的最小部分。缺点是分配的块的大小都是2的幂，会导致内部碎片。该算法的好处是在回收内存时，可以判断其伙伴是否空闲，若空闲则合并，如此向上回溯，直到合并成整个块。

  ![image-20220925164008361](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220925164008361.png)

* **分离空闲列表**——若某个程序频繁的请求特定几种大小的内存，则设置一个专用的空闲列表管理这几种特定大小的空闲内存。这种特定大小的内存分配和释放都很快。其他非特定大小的内存的分配则交给通用空闲内存。如：厚块分配算法。

## 18. 分页——虚拟内存向物理内存映射的方案二

### （1）分页概念

* 分段是将**虚拟地址空间**按照逻辑/功能（代码、堆、栈）划分为段，再通过基址、段内偏移映射到物理地址。这样的划分方法，由于是按照功能划分，各段的大小不定，容易在分配时造成外部碎片。
* 设想：如果将虚拟地址空间都划分为相同的大小的单元，分配时只要分配个单元即可，将不会因为分配造成外部碎片，同时也提高了分配、释放的效率。因此，将这些相同大小的单元称为**页**，页的大小都是相同的，Linux默认页大小是4KB。这种划分方法称为分页。
* 虚拟地址空间的每个页，映射到物理内存上一个**大小相同**的单元，称为**页帧**。

### （2）页表

* 页表是现代OS管理内存的一个最核心的数据结构，存储**虚拟页号VPN**到**物理内存页帧号PFN**之间的映射关系。

* 页表是每个进程都有的数据结构，OS会为每一个进程都管理一个页表，记录其虚拟地址空间到物理内存的映射。

* 假设虚拟地址有6位，可编码64B。页表大小16B，则虚拟地址空间被划分为4个页表。以虚拟地址的2bit编码4个页表（00/01/10/11），4bit寻址某一个页表的16B（0000~1111）。

  **所以VPN为2bit，偏移量offset为4bit。**

  ![image-20220925212037363](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220925212037363.png)}

* 通过VPN找到页表项，从页表项中读取PFN，偏移量offset在虚拟空间和物理内存中都相同。将PFN和offset组合可得物理地址。

  ![image-20220926150815345](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220926150815345.png)

* 页表项中存储了哪些信息？

  > 物理页帧号PFN
  >
  > 保护位：对应物理页是否允许读取、写入、执行
  >
  > 存在位：对应物理页是在内存上还是磁盘上
  >
  > 脏位：页加载进内存后是否被修改过
  >
  > 参考位：追踪页是否被访问
  >
  > ![image-20220926151051012](https://raw.githubusercontent.com/WangKun233/ImageHost/main/image-20220926151051012.png)

* 从虚拟地址到物理地址的详细过程

  > **PTBR(PageTableBaseRegister)**：页表基址寄存器，存放页表的起始地址
  >
  > **VirtualAddress**：虚拟地址
  >
  > **VPN**：虚拟页号
  >
  > **VPN_MASK**：虚拟页号掩码
  >
  > **SHIFT**：虚拟地址和掩码与后的右移位数
  >
  > **PTEAddr**：页表项物理地址
  >
  > **PTE(Page Table Entry)**：页表项
  >
  > **offset**：偏移量
  >
  > **PFN**：物理页帧号
  >
  > **PFN_SHIFT**：物理页帧号左移位数（要放到偏移量的左侧高位）
  >
  > **PhysAddr**：物理地址

  ![image-20220926163831174](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220926163831174.png)

  > ①VirtualAddress和VPN_MASK相与，将虚拟页号的位保留下来，右移SHIFT位将其从高位移动到低位。得到虚拟页号VPN
  >
  > ②PTE是页表项，sizeof(PTE)是页表项的大小，VPN*sizeof(PTE)+页表起始物理地址PTBR，可得虚拟页号为VPN的页表项的物理地址PTEAddr
  >
  > ③以PTEAddr进行内存访问AccessMemory(PTEAddr)获取该页表项的内容PTE
  >
  > ④VirtualAddress和OFFSET_MASK相与，得到偏移量offset
  >
  > ⑤从PTE中获取物理页帧号PTE.PFN，左移PFN_SHIFT到高位。再与offset或得到完整物理地址PhysAddr
  >
  > ⑥访问物理地址PhysAddr，AccessMemory(PhysAddr)

### （3）到目前为止的分页机制影响了性能

每次访问虚拟内存映射的物理内存，都需要访问页表项中的内容（18-(2)中的③），而页表存储于内存，增加了一次对内存的访问。

## 19. TLB——快速地址转换

### （1）为什么要引入TLB？

如18-(3)所述，基本的分页因为每次访问内存都额外增加了一次内存访问（访问内存中的页表），影响了性能。

### （2）概念

增加硬件：**地址转换缓存TLB**

缓存什么：某些页表项中虚拟页VPN到物理页帧PFN的映射

过程：每次内存访问时，不再是直接去访问内存中的页表获取映射。而是先去TLB中查找是否有期望的映射，若有就完成地址转换，而不用去页表中读取，提高了性能。

## 20. 如何让页表更小



# 并发

